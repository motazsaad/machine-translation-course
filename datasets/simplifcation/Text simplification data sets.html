<html>
<head>
<title>Text simplification data sets</title>
</head>
<body>
<h2>Text simplification data sets</h2>
<p>If you use this data, please send me (David Kauchak) an e-mail and let me know what project you're working on.</p>

<h3>Wikipedia Data Sets</h3>

<p>Two different versions of the data set now exist.  Both were generated by aligning Simple English Wikipedia and English Wikipedia.  A complete description of the extraction process can be found in "<a href="../papers/kauchak11simple.short.pdf">Simple English Wikipedia: A New Simplification Task</a>", William Coster and David Kauchak (2011).  In Proceedings of ACL (short paper).</p>

<p>For questions regarding either version of the data set, contact David Kauchak at Middlebury College.

<h4>Version 1.0</h4>

<p>The original version of the data set created from Wikipeda pages downloaded in May 2010.  The data set contains 137K aligned sentences pairs based on those sentences that have a similarity above 0.50.  Higher precision alignments may be obtained by TF-IDF thresholding at higher levels.</p>

<a href="data.v1/data.v1.tar.gz">Version 1.0 data</a> &nbsp;&nbsp;&nbsp;(<a href="data.v1/data.v1.split.tar.gz">split into train, tune and test</a>)

<h4>Version 2.0</h4>

<p>Updated version of the data set from Wikipedia pages downloaded in May 2011.  This data set was used in "<a href="https://aclweb.org/anthology-new/P/P13/P13-1151.pdf">Improving Text Simplification Language Modeling Using Unsimplified Text Data</a>", David Kauchak (2013). In Proceedings of ACL.  The versions below are slightly different (larger) than the data used in the paper.  For the data used in the paper, please contact me.</p>

<p>This data set contains two parts, a sentence-aligned part and a document aligned part:

<ul>
<li><i>Sentence-aligned</i>: Updated version of the version 1.0 sentence-aligned data set with updated Wikipedia data and improved text processing.  The data set contains 167K aligned sentence pairs.

<p><a href="data.v2/sentence-aligned.v2.tar.gz">Version 2.0 sentence-aligned data</a></p>
</li>

<li><i>Document-aligned</i>: The text from 60K English Wikipedia and Simple English Wikipedia articles paired based on the titles.  The data set contains <b>all</b> Simple English Wikipedia articles that also have a corresponding article in English Wikipedia.

<p><a href="data.v2/document-aligned.v2.tar.gz">Version 2.0 document-aligned data</a></p>
</li>
</ul>

<h3>Mechanical Turk Lexical Simplification Data Set</h3>

Available <a href="lex.mturk.14/lex.mturk.14.tar.gz">here</a>.

<p>
For more information and to cite, see:<br>Colby Horn, Katie Manduca and David Kauchak (2014). Learning a Lexical Simplifier Using Wikipedia. In <i>Proceedings of ACL (short paper)</i>.

<h3>Mechanical Turk Word Substitution Filtering Data Set</h3>

Available <a href="word_filtering/MTurk_annotations.zip">here</a>

<p>
For more information and to cite, see:<br>David Kauchak, Jorge Apricio and Gondy Leroy</a> (2022). Improving the Quality of Suggestions for Medical Text Simplification Tools. In <i>Proceedings of AMIA Informatics Summit</i>.



</body>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-42469154-1', 'middlebury.edu');
  ga('send', 'pageview');

</script>

</html>
